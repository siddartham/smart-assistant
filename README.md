---

# ðŸ§  Smart Assistant â€“ Document + Structured Data Chatbot

An AI-powered assistant that allows users to **chat with documents** and **structured datasets** through a conversational UI. It performs **semantic search**, **section-wise summarization**, and **structured data lookup** â€” intelligently switching tools based on user queries and data availability.

---

## ðŸ”§ Features

### ðŸ“„ Document Understanding

* Upload and index documents (`.pdf`, `.docx`, `.txt`)
* Ask questions about content (retrieves facts using reranked document chunks)
* Summarize specific sections, generate insights, extract key points

### ðŸ“Š Structured Data Interaction

* Accesses an in-memory DataFrame when document data is insufficient
* Automatically escalates to tabular querying for numeric, comparative, or summary-based questions

### ðŸ§  Tool Orchestration via LangGraph

* Dynamically selects tools:

  * `document_search` â†’ factual queries
  * `summarization_tool` â†’ high-level overviews
  * `structured_data_lookup` â†’ fallback for data not found in documents
* Reranking via `CrossEncoder` improves search relevance

### ðŸ—‚ï¸ Conversational Memory

* Maintains context across chat turns via `LangGraph` memory
* Understands follow-ups like â€œWhat more about Product A?â€

### ðŸª„ Transparent Reasoning

Every response includes:

* Final Answer
* Tool Trace
* Reasoning
* Source of truth (document or structured)

---

## ðŸš€ Getting Started

### 1. ðŸ“¦ Install Dependencies

```bash
uv sync  # or pip install -r requirements.txt if using pip
```

---

### 2. â–¶ï¸ Launch the App

```bash
python -m src.app
```

---

### 3. ðŸ§ª Try Queries Like:

| Goal                               | Sample Queries                                                | Tool Path                                     |
| ---------------------------------- | ------------------------------------------------------------- | --------------------------------------------- |
| ðŸ“˜ Ask for specific data from docs | *"Whatâ€™s the North region revenue for Product C?"*            | `document_search`                             |
| ðŸ“‰ Escalate to data lookup         | *"Whatâ€™s the profit margin of Product A across all regions?"* | `document_search â†’ structured_data_lookup`    |
| ðŸ§¾ Summarize section               | *"Give a high-level summary of Q4 performance"*               | `summarization_tool`                          |
| ðŸ“Š Summary fails â†’ table           | *"Compare online vs offline sales by region"*                 | `summarization_tool â†’ structured_data_lookup` |

---

## ðŸ“ Project Structure

```bash
.
â”œâ”€â”€ app.py               # Gradio UI
â”œâ”€â”€ graph.py             # LangGraph logic with assistant orchestration
â”œâ”€â”€ indexer.py           # Loads and indexes PDF, DOCX, TXT with embeddings
â”œâ”€â”€ tools.py             # Tool definitions: search, summarize, structured query
â”œâ”€â”€ logger.py            # Logging + callback tracing
â”œâ”€â”€ pyproject.toml       # Python project configuration
â”œâ”€â”€ uv.lock              # Lockfile for uv + reproducible builds
â””â”€â”€ vectorstore/index/   # FAISS vector index (generated at runtime)
```

---

## ðŸ“š Data Used

* ðŸ“„ **Document Corpus**: Any uploaded `.pdf`, `.txt`, or `.docx`
* ðŸ“Š **Structured DataFrame**: Pre-loaded in-memory dummy data, with:

  ```python
  columns = ["product", "region", "revenue", "online_pct", "profit_margin", "growth_qoq", "avg_order_value"]
  ```

---

## ðŸ§  Behind the Scenes

* **Semantic Search** via FAISS + `sentence-transformers`
* **Relevance Reranking** via `cross-encoder/ms-marco-MiniLM-L-6-v2`
* **LLM**: `gpt-4o-mini` via `langchain-openai`
* **Prompt Reflection**: Decides whether to escalate based on LLM's self-check

---


Absolutely â€” here's the updated `README.md` section including all `.env` assumptions used in your code:

---

## ðŸ” Environment Variables (`.env`)

To configure the assistant securely, you need to define the following environment variables in a `.env` file (at the root of the project)(`src`)):

```ini
# .env

OPENAI_API_KEY=your_openai_key_here
```

### ðŸ” Notes:

* `OPENAI_API_KEY` is used for invoking the LLM (`ChatOpenAI`).
* You can configure the model used (optional)


> The environment variables are loaded using `python-dotenv` and automatically picked up when running `app.py`.

---

## ðŸ§  TODO

* **Refactoring of Prompt into separate module** 
* **Refactoring of tools into subpackage with module for each** 
---